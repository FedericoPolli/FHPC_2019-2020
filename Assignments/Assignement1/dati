Section 0

Laptop:
	Model
	CPU: Intel(R) Core(TM) i7-7500U @ 2.70GHz
	2 cores
	FLOPS per cycle: 16 (Intel Kaby Lake architecture, https://en.wikipedia.org/wiki/FLOPS)
	Theoretical Peak Performance:2*2.7*16=86.4 GFLOPS
	Top 1 until november 1993 (https://en.wikipedia.org/wiki/Numerical_Wind_Tunnel_(Japan))

Cell:
	Sustained Peak Performance 1209 MFLOPS (Matrix size 2500)
	CPU: Octa core, 2 GHz, Qualcomm Snapdragon 625, 2 Flops per cycle
	Theoretical Peak Performance: 32 GFLOPS
	RAM: 4 Gb
	1982 Cray X-MP 800 MFLOPS
	1985 Cray-2 1.9 GFLOPS

Section 1
	Modify scalability by sending partial sums to other processor, so to use more the other processors.

Section 2

Strong Scaling:

Pi.c time on N=10000000 is 0.19 sec

Mpi.C time on N=10000000 with 1 processor is 1.7 sec  --> parallel overhead caused by MPI on cluster is approx 1.5 sec (parallel overhead on laptop 0.35 sec)
walltime on master processor is 0.2 sec

Mpi.C time on N=10000000 with 2 processors is 1.62 sec
walltime on master processor is 0.1 sec

Mpi.C time on N=10000000 with 4 processors is 1.59 sec
walltime on master processor is 0.05 sec

Mpi.C time on N=10000000 with 8 processors is 1.68 sec
walltime on master processor is 0.028 sec

Mpi.C time on N=10000000 with 16 processors is 1.85 sec
walltime on master processor is 0.015 sec

Mpi.C time on N=10000000 with 20 processors is 1.88 sec
walltime on master processor is 0.011 sec



Pi.c time on N=100000000 is 1.95 sec

Mpi.C time on N=100000000 with 1 processor is 3.5 sec  --> parallel overhead caused by MPI on cluster is approx 1.5 sec
walltime on master processor is 1.98 sec

Mpi.C time on N=100000000 with 2 processors is 2.54 sec
walltime on master processor is 1.02 sec

Mpi.C time on N=100000000 with 4 processors is 2.03 sec
walltime on master processor is 0.51 sec

Mpi.C time on N=100000000 with 8 processors is 1.89 sec
walltime on master processor is 0.27 sec

Mpi.C time on N=100000000 with 16 processors is 1.89 sec
walltime on master processor is 0.14 sec

Mpi.C time on N=100000000 with 20 processors is 1.97 sec
walltime on master processor is 0.12 sec




Pi.c time on N=1000000000 is 19.54 sec

Mpi.C time on N=1000000000 with 1 processors is 21.2 sec
walltime on master processor is 19.5 sec

Mpi.C time on N=1000000000 with 2 processors is 11.74 sec
walltime on master processor is 10.2 sec

Mpi.C time on N=1000000000 with 4 processors is 6.66 sec
walltime on master processor is 5.12 sec

Mpi.C time on N=1000000000 with 8 processors is 4.31 sec
walltime on master processor is 2.71 sec

Mpi.C time on N=1000000000 with 16 processors is 3.20 sec
walltime on master processor is 1.45 sec

Mpi.C time on N=1000000000 with 20 processors is 2.96 sec
walltime on master processor is 1.15 sec




Parallel overhead:

Consider the maximum of time of processors (should be the master)

Execute code without summing -> result is:
1 proc 1.52 sec
2 proc 1.53 sec
4 proc 1.57 sec
8 proc 1.62 sec
12 proc 1.71 s
16 proc 1.82 s
20 proc 1.85 s



Weak scaling:

Constant N/proc=500000000

Pi.c time is 0.98 sec

Mpi.C time with 1 processors is 2.50 sec
walltime on master processor is 0.98 sec

Mpi.C time with 2 processors is 2.52 sec
walltime on master processor is 1.02 sec

Mpi.C time on with 4 processors is 2.56 sec
walltime on master processor is 1.02 sec

Mpi.C time on with 8 processors is 2.71 sec
walltime on master processor is 1.08 sec

Mpi.C time on with 12 processors is 2.85 sec
walltime on master processor is 1.15 sec

Mpi.C time on with 16 processors is 2.89 sec
walltime on master processor is 1.15 sec

Mpi.C time on with 20 processors is 2.94 sec
walltime on master processor is 1.16 sec








Section 4 


N=10.000.000

serial time 0.04 sec

time with 1 processors is 1.55 sec
walltime on master processor is 0.02 sec

time with 2 processors is 1.55 sec
walltime on master processor is 0.012 sec

time with 4 processors is 1.57 sec
walltime on master processor is 0.007 sec

time with 8 processors is 1.62 sec
walltime on master processor is 0.005 sec

time with 16 processors is 1.83 sec
walltime on master processor is 0.004 sec

time with 20 processors is 1.84 sec
walltime on master processor is 0.006 sec




N=100.000.000

serial time 0.23 sec

time with 1 processors is 1.72 sec
walltime on master processor is 0.23 sec

time with 2 processors is 1.62 sec
walltime on master processor is 0.12 sec

time with 4 processors is 1.58 sec
walltime on master processor is 0.06 sec

time with 8 processors is 1.65 sec
walltime on master processor is 0.03 sec

time with 16 processors is 1.84 sec
walltime on master processor is 0.02 sec

time with 20 processors is 1.85 sec
walltime on master processor is 0.02 sec
 comm time 0.001


N=1.000.000.000

serial time 2.32 sec

time with 1 processors is 3.88 sec
walltime on master processor is 2.37 sec

time with 2 processors is 2.75 sec
walltime on master processor is 1.23 sec

time with 4 processors is 2.17 sec
walltime on master processor is 0.62 sec

time with 8 processors is 1.95 sec
walltime on master processor is 0.33 sec

time with 16 processors is 1.89 sec
walltime on master processor is 0.18 sec

time with 20 processors is 1.95 sec
walltime on master processor is 0.14 sec



reading time=0.0001, comm time=0.0001


